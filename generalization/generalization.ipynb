{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === 1. Setup ===\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Dummy function to simulate judgment distributions (example)\n",
    "def distribution(state_label):\n",
    "    # Returns a ternary distribution {-1, 0, 1} for a given label\n",
    "    return {-1: 0.1, 0: 0.2, 1: 0.7} if state_label == 'positive' else {-1: 0.6, 0: 0.3, 1: 0.1}\n",
    "\n",
    "# === 2. Simulated classification and scenario data (example structure) ===\n",
    "classification = {\n",
    "    'D_1': {\n",
    "        'lying_to_support': {\n",
    "            'States': [\n",
    "                ('s1', 'positive'),\n",
    "                ('s2', 'negative')\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "scenarios = [\n",
    "    {'id': 's1', 'scenario': \"A mother lies about Santa Claus to her child.\"},\n",
    "    {'id': 's2', 'scenario': \"A nurse tells an elderly patient that their family is 'just running late' every day, even though no one is visiting.\"}\n",
    "]\n",
    "\n",
    "# === 3. Build the group structure: mapping scenario ID, context, and judgment distribution ===\n",
    "groups = []\n",
    "for context in classification['D_1']:\n",
    "    for state in classification['D_1'][context]['States']:\n",
    "        scenario_text = [d['scenario'] for d in scenarios if d['id'] == state[0]][0]\n",
    "        groups.append({\n",
    "            'id': state[0],\n",
    "            'distrib': distribution(state[1]),\n",
    "            'context': context,\n",
    "            'scenario': scenario_text\n",
    "        })\n",
    "\n",
    "# === 4. Feature-annotated dilemmas (normally produced by GPT or expert tagging) ===\n",
    "# These are example inputs for the regression task\n",
    "dilemmas = [\n",
    "    {\n",
    "        \"scenario\": \"A mother lies about Santa Claus to her child.\",\n",
    "        \"Comfort-driven\": 1,\n",
    "        \"Low-stakes consequences\": 1,\n",
    "        \"Preserves emotional well-being\": 1,\n",
    "        \"Strategic deception\": 0,\n",
    "        \"Role-based justification\": 0,\n",
    "        \"Protective intent\": 0,\n",
    "        \"Avoidance of emotional burden\": 0,\n",
    "        \"Personal relationship context\": 1,\n",
    "        \"Soothing narrative for loss\": 0,\n",
    "        \"Protective fabrication\": 0,\n",
    "        \"Professional authority used\": 0,\n",
    "        \"Ethical tension\": 0,\n",
    "        \"Truth withheld to maintain hope\": 0\n",
    "    },\n",
    "    {\n",
    "        \"scenario\": \"A nurse tells an elderly patient that their family is 'just running late' every day, even though no one is visiting.\",\n",
    "        \"Comfort-driven\": 1,\n",
    "        \"Low-stakes consequences\": 1,\n",
    "        \"Preserves emotional well-being\": 1,\n",
    "        \"Strategic deception\": 0,\n",
    "        \"Role-based justification\": 1,\n",
    "        \"Protective intent\": 1,\n",
    "        \"Avoidance of emotional burden\": 0,\n",
    "        \"Personal relationship context\": 0,\n",
    "        \"Soothing narrative for loss\": 0,\n",
    "        \"Protective fabrication\": 0,\n",
    "        \"Professional authority used\": 1,\n",
    "        \"Ethical tension\": 1,\n",
    "        \"Truth withheld to maintain hope\": 1\n",
    "    }\n",
    "]\n",
    "\n",
    "# === 5. Enrich dilemmas with context, id, and judgment distribution ===\n",
    "for dilemma in dilemmas:\n",
    "    for d in groups:\n",
    "        if d['scenario'] == dilemma['scenario']:\n",
    "            dilemma['context'] = d['context']\n",
    "            dilemma['distrib'] = d['distrib']\n",
    "            dilemma['id'] = d['id']\n",
    "\n",
    "# === 6. Convert to DataFrame for analysis ===\n",
    "df = pd.DataFrame(dilemmas)\n",
    "\n",
    "# Extract -1 and +1 probability from the distribution\n",
    "df['prob_-1'] = df['distrib'].apply(lambda d: d.get(-1, 0))\n",
    "df['prob_1'] = df['distrib'].apply(lambda d: d.get(1, 0))\n",
    "\n",
    "# === 7. Define feature columns ===\n",
    "feature_cols = [\n",
    "    'Comfort-driven', 'Low-stakes consequences', 'Preserves emotional well-being',\n",
    "    'Strategic deception', 'Role-based justification', 'Protective intent',\n",
    "    'Avoidance of emotional burden', 'Personal relationship context',\n",
    "    'Soothing narrative for loss', 'Protective fabrication',\n",
    "    'Professional authority used', 'Ethical tension', 'Truth withheld to maintain hope'\n",
    "]\n",
    "\n",
    "# === 8. Train linear regression models ===\n",
    "X = df[feature_cols]\n",
    "\n",
    "model_neg1 = LinearRegression().fit(X, df['prob_-1'])\n",
    "model_1 = LinearRegression().fit(X, df['prob_1'])\n",
    "\n",
    "# === 9. Extract and sort feature weights ===\n",
    "coefficients_neg1 = pd.Series(model_neg1.coef_, index=feature_cols).sort_values(ascending=False)\n",
    "coefficients_1 = pd.Series(model_1.coef_, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "# Compute neutral weight (1 - prob_-1 - prob_1) and its pseudo-coefficients\n",
    "coefficients_neutral = 1 - coefficients_1 - coefficients_neg1\n",
    "coefficients_neutral = coefficients_neutral.sort_values(ascending=False)\n",
    "\n",
    "# Print intercepts\n",
    "print(\"Intercept for -1 regression:\", model_neg1.intercept_)\n",
    "print(\"Intercept for +1 regression:\", model_1.intercept_)\n",
    "print(\"Intercept for neutral (inferred):\", 1 - model_neg1.intercept_ - model_1.intercept_)\n",
    "\n",
    "# === 10. Visualize regression weights ===\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "coefficients_neg1.plot(kind='barh', ax=axs[0], color='red')\n",
    "axs[0].axvline(0, color='black')\n",
    "axs[0].set_title('Feature Weights for -1 Judgment')\n",
    "\n",
    "coefficients_1.plot(kind='barh', ax=axs[1], color='green')\n",
    "axs[1].axvline(0, color='black')\n",
    "axs[1].set_title('Feature Weights for +1 Judgment')\n",
    "\n",
    "coefficients_neutral.plot(kind='barh', ax=axs[2], color='gray')\n",
    "axs[2].axvline(0, color='black')\n",
    "axs[2].set_title('Feature Weights for Neutral Judgment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('generalization_D1.pdf')\n",
    "plt.show()\n",
    "\n",
    "# === 11. Example: Compute and plot coordinates in (prob_1, prob_-1) space ===\n",
    "# Dummy predict function (should match the model output)\n",
    "def predict(dilemma):\n",
    "    x = pd.DataFrame([dilemma])[feature_cols]\n",
    "    p1 = model_1.predict(x)[0]\n",
    "    p_1 = model_neg1.predict(x)[0]\n",
    "    return p1, p_1\n",
    "\n",
    "# Generate coordinates\n",
    "coordinates_D1 = [[], []]\n",
    "for dilemma in dilemmas:\n",
    "    p1, p_1 = predict(dilemma)\n",
    "    coordinates_D1[0].append(p1)\n",
    "    coordinates_D1[1].append(p_1)\n",
    "\n",
    "# Plot the 2D projection\n",
    "plt.scatter(coordinates_D1[1], coordinates_D1[0], color='purple', s=50)\n",
    "plt.xlabel('P(-1)')\n",
    "plt.ylabel('P(+1)')\n",
    "plt.title('To lie to support â€” scenario projection')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.savefig('coordinates_D1.pdf')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
